{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from footballsquads_handler import footballsquads_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = footballsquads_handler(\".cache_footballsquads/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh.scrape_archive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh.cache_to_db(\"GDE.db\", leagues=[\"GER-Bundesliga\", \"GER-Bundesliga2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"/home/morten/Develop/packing-report/Goal-Difference-Elo-GDE/.cache_footballsquads/ger-2021-2022-gerbun-monchen.pckl\",'rb')\n",
    "to = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(url):\n",
    "    all_rows = []\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(\"http://www.footballsquads.co.uk/ger/2021-2022/bundes/monchen.htm\")\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Find the table you want to scrape by inspecting the HTML source\n",
    "        table = soup.find(\"div\", {\"id\": \"main\"})\n",
    "\n",
    "        if table:\n",
    "            # Extract table rows\n",
    "            rows = table.find_all(\"tr\")\n",
    "\n",
    "            # Loop through rows and extract data\n",
    "            for row in rows:\n",
    "                # Extract table data from each row\n",
    "                cells = row.find_all([\"th\", \"td\", \"i\"], recursive=True)\n",
    "                row_data = []\n",
    "                for cell in cells:\n",
    "                    # Check if the cell contains italic text\n",
    "                    italic_text = cell.find(\"i\")\n",
    "                    if italic_text:\n",
    "                        # If italic text is present, add it to row_data\n",
    "                        row_data.append(italic_text.get_text(strip=True))\n",
    "                    else:\n",
    "                        # If no italic text, add the regular text\n",
    "                        row_data.append(cell.get_text(strip=True))\n",
    "                # Print row data\n",
    "                all_rows.append(row_data)\n",
    "        else:\n",
    "            print(\"Table not found on the page.\")\n",
    "        print(all_rows)\n",
    "    else:\n",
    "        print(\"Failed to fetch the page. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data found in cache, skip\n",
      "[['Number', 'Name', 'Nat', 'Pos', 'Height', 'Weight', 'Date of Birth', 'Birth Place', 'Previous Club'], ['1', 'Yann Sommer', 'SUI', 'G', '1.83', '77', '17-12-88', 'Morges', 'Basel'], ['2', '', '', '', '', '', '', '', ''], ['3', '', '', '', '', '', '', '', ''], ['4', 'Mamadou Doucouré', 'FRA', 'D', '1.82', '75', '21-05-98', 'Dakar', 'Paris St-Germain'], ['5', 'Marvin Friedrich', 'GER', 'D', '1.90', '74', '13-12-95', 'Kassel', 'Union Berlin'], ['6', 'Christoph Kramer', 'GER', 'M', '1.90', '73', '19-02-91', 'Solingen', 'Bayer Leverkusen'], ['7', 'Patrick Herrmann', 'GER', 'F', '1.79', '69', '12-02-91', 'Saarbrücken', 'Saarbrücken'], ['8', '', '', '', '', '', '', '', ''], ['9', '', '', '', '', '', '', '', ''], ['10', 'Marcus Thuram', 'FRA', 'F', '1.88', '80', '06-08-97', 'Parma', 'Guingamp'], ['11', '', '', '', '', '', '', '', ''], ['12', '', '', '', '', '', '', '', ''], ['13', 'Lars Stindl', 'GER', 'M', '1.80', '73', '26-08-88', 'Waghäusel', 'Hannover 96'], ['14', 'Alassane Pléa', 'FRA', 'F', '1.80', '72', '10-03-93', 'Lille', 'Nice'], ['15', 'Jordan Beyer', 'GER', 'D', '1.87', '80', '19-05-00', 'Kempen', 'Fortuna Düsseldorf'], ['16', '', '', '', '', '', '', '', ''], ['17', 'Kouadio Koné', 'FRA', 'M', '1.76', '71', '17-05-01', 'Colombes', 'Toulouse'], ['18', 'Stefan Lainer', 'AUT', 'D', '1.75', '70', '27-08-92', 'Salzburg', 'Red Bull Salzburg'], ['19', '', '', '', '', '', '', '', ''], ['20', 'Luca Netz', 'GER', 'D', '1.80', '74', '15-05-03', 'Buch', 'Hertha Berlin'], ['21', 'Tobias Sippel', 'GER', 'G', '1.80', '79', '22-03-88', 'Bad Dürkheim', 'Kaiserslautern'], ['22', 'László Bénes', 'SVK', 'M', '1.73', '60', '09-09-97', 'Dunajská Streda', 'MSK Žilina'], ['23', 'Jonas Hofmann', 'GER', 'M', '1.76', '65', '14-07-92', 'Heidelberg', 'Borussia Dortmund'], ['24', 'Tony Jantschke', 'GER', 'D', '1.77', '69', '07-04-90', 'Hoyerswerda', 'None'], ['25', 'Ramy Bensebaini', 'ALG', 'D', '1.86', '75', '16-04-95', 'Constantine', 'Rennes'], ['26', '', '', '', '', '', '', '', ''], ['27', '', '', '', '', '', '', '', ''], ['28', 'Matthias Ginter', 'GER', 'D', '1.87', '82', '19-01-94', 'March', 'Borussia Dortmund'], ['29', 'Joe Scally', 'USA', 'D', '1.78', '67', '31-12-02', 'Lake Grove', 'New York C'], ['30', 'Nico Elvedi', 'SUI', 'D', '1.88', '74', '30-09-96', 'Zürich', 'Zürich'], ['31', '', '', '', '', '', '', '', ''], ['32', 'Florian Neuhaus', 'GER', 'M', '1.79', '64', '16-03-97', 'Landsberg', '1860 Munich'], ['33', 'Kaan Kurt', 'GER', 'D', '1.74', '60', '21-12-01', 'Moers', 'Duisburg'], ['34', 'Conor Noß', 'IRL', 'M', '1.81', '72', '01-01-01', 'Düsseldorf', 'None'], ['35', '', '', '', '', '', '', '', ''], ['36', 'Breel Embolo', 'SUI', 'F', '1.84', '71', '14-02-97', 'Yaoundé', 'Schalke'], ['37', 'Keanan Bennetts', 'ENG', 'F', '1.83', '73', '09-03-99', 'Hendon', 'Tottenham H'], ['38', '', '', '', '', '', '', '', ''], ['39', 'Mika Schroers', 'GER', 'F', '1.81', '65', '04-02-02', 'Kempen', 'None'], ['40', '', '', '', '', '', '', '', ''], ['41', 'Jan Olschowsky', 'GER', 'G', '1.82', '79', '18-11-01', 'Neuss', 'None'], ['43', 'Tom Gaal', 'GER', 'D', '1.95', '87', '03-03-01', 'Mönchengladbach', 'Wolfsburg'], ['46', 'Jonas Kersken', 'GER', 'G', '1.90', '88', '01-09-00', 'Düsseldorf', 'RW Essen'], ['Players no longer at this club'], ['Number', 'Name', 'Nat', 'Pos', 'Height', 'Weight', 'Date of Birth', 'Birth Place', 'New Club'], ['40', 'Andreas Poulsen', 'DEN', 'D', '1.88', '80', '13-10-99', 'Ikast', 'Ingolstadt (On Loan)'], ['27', 'Famana Quizera', 'POR', 'M', '1.72', '70', '25-04-02', 'Bissau', 'Académico Viseu (On Loan)'], ['26', 'Torben Müsel', 'GER', 'M', '1.85', '76', '25-07-99', 'Grünstadt', 'Eupen (On Loan)'], ['11', 'Hannes Wolf', 'AUT', 'M', '1.79', '66', '16-04-99', 'Graz', 'Swansea C (On Loan)'], ['8', 'Denis Zakaria', 'SUI', 'M', '1.91', '76', '20-11-96', 'Kinshasa', 'Juventus'], ['', '', '', '', '', '', '', '', '']]\n",
      "None Data found!\n"
     ]
    }
   ],
   "source": [
    "scrape_url = f\"http://www.footballsquads.co.uk/ger/2021-2022/bundes/monchen.htm\"\n",
    "team_name = \"monchen\"\n",
    "file_path = f\"ger-bundes-2020-2021-{team_name}.pckl\"\n",
    "if file_path not in os.listdir(\"/home/morten/Develop/packing-report/Goal-Difference-Elo-GDE/.cache_footballsquads\"):\n",
    "    print(\"Scraping \", scrape_url)\n",
    "else:\n",
    "    print(\"Data found in cache, skip\")\n",
    "data = get_table(scrape_url)\n",
    "if not data:\n",
    "    print(\"None Data found!\")\n",
    "with open(\"/home/morten/Develop/packing-report/Goal-Difference-Elo-GDE/.cache_footballsquads/\" + file_path, 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Thuram\n",
      "11 \n",
      "Wolf \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data='''<table>\n",
    "<tr>\n",
    "   <td>10</td>\n",
    "   <td>Thuram</td>\n",
    "</tr>\n",
    "<tr>\n",
    "   <td>11</td>\n",
    "   <td>\n",
    "      <i>Wolf </i>  \n",
    "   </td>\n",
    "</tr>\n",
    "</table>'''\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(data,'html.parser')\n",
    "\n",
    "for child in soup.find('table').findChildren(\"tr\" , recursive=False):\n",
    "  tdlist = []\n",
    "  if child.find('table'):\n",
    "     for td in child.findChildren(\"td\", recursive=False):\n",
    "         print(td.next_element.strip())\n",
    "         for td1 in td.findChildren(\"table\", recursive=False):\n",
    "             for child1 in td1.findChildren(\"tr\", recursive=False):\n",
    "                 for child2 in child1.findChildren(\"td\", recursive=False):\n",
    "                     tdlist.append(child2.text)\n",
    "                 print(' '.join(tdlist))\n",
    "                 print(child2.next_element.next_element.strip())\n",
    "  else:\n",
    "     for td in child.findChildren(\"td\" , recursive=False):\n",
    "         tdlist.append(td.text)\n",
    "     print(' '.join(tdlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packing-report",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
