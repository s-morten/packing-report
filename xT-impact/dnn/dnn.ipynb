{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 11:37:25.441711: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-27 11:37:25.611452: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-27 11:37:25.611485: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-27 11:37:26.407790: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-27 11:37:26.407883: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-27 11:37:26.407892: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data_acquisition/data_0.3/data_game_values_train.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_mean = np.mean(np.mean(train_data[\"home_xG\"]) + np.mean(train_data[\"away_xG\"]))\n",
    "xg_against_mean = np.mean(np.mean(train_data[\"home_xg_against\"]) + np.mean(train_data[\"away_xg_against\"]))\n",
    "\n",
    "xt_mean = np.mean(np.mean(train_data[\"home_xT_all\"]) + np.mean(train_data[\"away_xT_all\"]))\n",
    "xt_against_mean = np.mean(np.mean(train_data[\"home_xt_all_against\"]) + np.mean(train_data[\"away_xt_all_against\"]))\n",
    "\n",
    "form_for_mean = np.mean(np.mean(train_data[\"ha_form_home_for\"] / 5) + np.mean(train_data[\"ha_form_away_for\"] / 5))\n",
    "form_against_mean = np.mean(np.mean(train_data[\"ha_form_home_against\"] / 5) + np.mean(train_data[\"ha_form_away_against\"] / 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.swapaxes(np.array([train_data[\"home_xG\"] - xg_mean, train_data[\"away_xg_against\"] - xg_against_mean,\n",
    "                                train_data[\"away_xG\"] - xg_mean, train_data[\"home_xg_against\"] - xg_against_mean,\n",
    "                                train_data[\"home_xT_all\"] - xt_mean, train_data[\"away_xt_all_against\"] - xt_against_mean,\n",
    "                                train_data[\"away_xT_all\"] - xt_mean, train_data[\"home_xt_all_against\"] - xt_against_mean]), 0, 1)\n",
    "\n",
    "# gi = np.swapaxes(np.array([train_data[\"home_gi\"], train_data[\"away_gi\"]]), 0, 1)\n",
    "\n",
    "form = np.swapaxes(np.array([(train_data[\"ha_form_home_for\"] / 5) - form_for_mean, (train_data[\"ha_form_home_against\"] / 5) - form_against_mean,\n",
    "                            (train_data[\"ha_form_away_for\"] / 5) - form_for_mean, (train_data[\"ha_form_away_against\"] / 5) - form_against_mean]), 0, 1)\n",
    "\n",
    "goals = np.swapaxes(np.array([train_data[\"home_score\"], train_data[\"away_score\"]]), 0, 1)\n",
    "\n",
    "elo_diff = np.swapaxes(np.array([(train_data[\"elo_home\"] / 1000) - (train_data[\"elo_away\"] / 1000)]), 0, 1)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals_clas = [np.array([1, 0, 0]) if x[0] > x[1] else np.array([0, 1, 0]) if x[0] == x[1] else np.array([0, 0, 1]) for x in goals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([features, form, elo_diff], axis=1)\n",
    "y = np.array(goals_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(26, input_shape=(13,), activation='relu'))\n",
    "model.add(Dense(52, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(3, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['mean_squared_error'])\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "609/609 [==============================] - 2s 2ms/step - loss: 0.5397 - mean_squared_error: 0.1811\n",
      "Epoch 2/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5169 - mean_squared_error: 0.1724\n",
      "Epoch 3/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5137 - mean_squared_error: 0.1713\n",
      "Epoch 4/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5123 - mean_squared_error: 0.1708\n",
      "Epoch 5/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5115 - mean_squared_error: 0.1705\n",
      "Epoch 6/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5106 - mean_squared_error: 0.1700\n",
      "Epoch 7/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5098 - mean_squared_error: 0.1698\n",
      "Epoch 8/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5103 - mean_squared_error: 0.1700\n",
      "Epoch 9/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5098 - mean_squared_error: 0.1699\n",
      "Epoch 10/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5103 - mean_squared_error: 0.1700\n",
      "Epoch 11/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5084 - mean_squared_error: 0.1693\n",
      "Epoch 12/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5079 - mean_squared_error: 0.1690\n",
      "Epoch 13/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5077 - mean_squared_error: 0.1692\n",
      "Epoch 14/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5076 - mean_squared_error: 0.1691\n",
      "Epoch 15/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5070 - mean_squared_error: 0.1688\n",
      "Epoch 16/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5072 - mean_squared_error: 0.1689\n",
      "Epoch 17/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5072 - mean_squared_error: 0.1690\n",
      "Epoch 18/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5059 - mean_squared_error: 0.1685\n",
      "Epoch 19/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5063 - mean_squared_error: 0.1687\n",
      "Epoch 20/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5057 - mean_squared_error: 0.1684\n",
      "Epoch 21/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5051 - mean_squared_error: 0.1682\n",
      "Epoch 22/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5057 - mean_squared_error: 0.1685\n",
      "Epoch 23/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5044 - mean_squared_error: 0.1680\n",
      "Epoch 24/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5033 - mean_squared_error: 0.1674\n",
      "Epoch 25/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5043 - mean_squared_error: 0.1680\n",
      "Epoch 26/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5036 - mean_squared_error: 0.1677\n",
      "Epoch 27/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5029 - mean_squared_error: 0.1675\n",
      "Epoch 28/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5036 - mean_squared_error: 0.1678\n",
      "Epoch 29/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5024 - mean_squared_error: 0.1674\n",
      "Epoch 30/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5022 - mean_squared_error: 0.1671\n",
      "Epoch 31/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5011 - mean_squared_error: 0.1669\n",
      "Epoch 32/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5017 - mean_squared_error: 0.1670\n",
      "Epoch 33/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5013 - mean_squared_error: 0.1669\n",
      "Epoch 34/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5009 - mean_squared_error: 0.1668\n",
      "Epoch 35/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5007 - mean_squared_error: 0.1667\n",
      "Epoch 36/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5016 - mean_squared_error: 0.1671\n",
      "Epoch 37/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5000 - mean_squared_error: 0.1664\n",
      "Epoch 38/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5014 - mean_squared_error: 0.1669\n",
      "Epoch 39/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.5002 - mean_squared_error: 0.1665\n",
      "Epoch 40/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4990 - mean_squared_error: 0.1662\n",
      "Epoch 41/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4995 - mean_squared_error: 0.1663\n",
      "Epoch 42/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4993 - mean_squared_error: 0.1661\n",
      "Epoch 43/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4985 - mean_squared_error: 0.1660\n",
      "Epoch 44/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4979 - mean_squared_error: 0.1656\n",
      "Epoch 45/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4982 - mean_squared_error: 0.1658\n",
      "Epoch 46/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4976 - mean_squared_error: 0.1657\n",
      "Epoch 47/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4981 - mean_squared_error: 0.1658\n",
      "Epoch 48/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4976 - mean_squared_error: 0.1656\n",
      "Epoch 49/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4966 - mean_squared_error: 0.1654\n",
      "Epoch 50/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4967 - mean_squared_error: 0.1653\n",
      "Epoch 51/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4963 - mean_squared_error: 0.1651\n",
      "Epoch 52/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4966 - mean_squared_error: 0.1653\n",
      "Epoch 53/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4949 - mean_squared_error: 0.1645\n",
      "Epoch 54/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4957 - mean_squared_error: 0.1650\n",
      "Epoch 55/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4950 - mean_squared_error: 0.1646\n",
      "Epoch 56/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4954 - mean_squared_error: 0.1650\n",
      "Epoch 57/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4944 - mean_squared_error: 0.1645\n",
      "Epoch 58/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4944 - mean_squared_error: 0.1646\n",
      "Epoch 59/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4931 - mean_squared_error: 0.1639\n",
      "Epoch 60/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4935 - mean_squared_error: 0.1641\n",
      "Epoch 61/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4931 - mean_squared_error: 0.1639\n",
      "Epoch 62/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4920 - mean_squared_error: 0.1637\n",
      "Epoch 63/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4928 - mean_squared_error: 0.1638\n",
      "Epoch 64/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4918 - mean_squared_error: 0.1636\n",
      "Epoch 65/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4915 - mean_squared_error: 0.1634\n",
      "Epoch 66/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4909 - mean_squared_error: 0.1633\n",
      "Epoch 67/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4916 - mean_squared_error: 0.1635\n",
      "Epoch 68/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4904 - mean_squared_error: 0.1630\n",
      "Epoch 69/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4894 - mean_squared_error: 0.1628\n",
      "Epoch 70/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4892 - mean_squared_error: 0.1626\n",
      "Epoch 71/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4898 - mean_squared_error: 0.1629\n",
      "Epoch 72/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4900 - mean_squared_error: 0.1629\n",
      "Epoch 73/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4885 - mean_squared_error: 0.1623\n",
      "Epoch 74/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4884 - mean_squared_error: 0.1624\n",
      "Epoch 75/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4879 - mean_squared_error: 0.1621\n",
      "Epoch 76/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4871 - mean_squared_error: 0.1618\n",
      "Epoch 77/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4875 - mean_squared_error: 0.1620\n",
      "Epoch 78/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4869 - mean_squared_error: 0.1617\n",
      "Epoch 79/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4864 - mean_squared_error: 0.1616\n",
      "Epoch 80/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4860 - mean_squared_error: 0.1612\n",
      "Epoch 81/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4859 - mean_squared_error: 0.1614\n",
      "Epoch 82/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4850 - mean_squared_error: 0.1611\n",
      "Epoch 83/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4843 - mean_squared_error: 0.1608\n",
      "Epoch 84/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4839 - mean_squared_error: 0.1607\n",
      "Epoch 85/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4841 - mean_squared_error: 0.1609\n",
      "Epoch 86/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4835 - mean_squared_error: 0.1606\n",
      "Epoch 87/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4829 - mean_squared_error: 0.1605\n",
      "Epoch 88/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4822 - mean_squared_error: 0.1602\n",
      "Epoch 89/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4824 - mean_squared_error: 0.1602\n",
      "Epoch 90/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4816 - mean_squared_error: 0.1599\n",
      "Epoch 91/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4816 - mean_squared_error: 0.1598\n",
      "Epoch 92/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4806 - mean_squared_error: 0.1596\n",
      "Epoch 93/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4800 - mean_squared_error: 0.1594\n",
      "Epoch 94/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4799 - mean_squared_error: 0.1593\n",
      "Epoch 95/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4795 - mean_squared_error: 0.1591\n",
      "Epoch 96/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4794 - mean_squared_error: 0.1591\n",
      "Epoch 97/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4780 - mean_squared_error: 0.1586\n",
      "Epoch 98/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4785 - mean_squared_error: 0.1588\n",
      "Epoch 99/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4776 - mean_squared_error: 0.1585\n",
      "Epoch 100/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4781 - mean_squared_error: 0.1587\n",
      "Epoch 101/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4769 - mean_squared_error: 0.1582\n",
      "Epoch 102/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4767 - mean_squared_error: 0.1581\n",
      "Epoch 103/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4770 - mean_squared_error: 0.1583\n",
      "Epoch 104/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4764 - mean_squared_error: 0.1581\n",
      "Epoch 105/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4763 - mean_squared_error: 0.1580\n",
      "Epoch 106/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4748 - mean_squared_error: 0.1574\n",
      "Epoch 107/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4749 - mean_squared_error: 0.1575\n",
      "Epoch 108/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4755 - mean_squared_error: 0.1578\n",
      "Epoch 109/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4742 - mean_squared_error: 0.1573\n",
      "Epoch 110/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4740 - mean_squared_error: 0.1573\n",
      "Epoch 111/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4735 - mean_squared_error: 0.1571\n",
      "Epoch 112/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4737 - mean_squared_error: 0.1570\n",
      "Epoch 113/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4731 - mean_squared_error: 0.1567\n",
      "Epoch 114/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4724 - mean_squared_error: 0.1567\n",
      "Epoch 115/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4713 - mean_squared_error: 0.1564\n",
      "Epoch 116/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4709 - mean_squared_error: 0.1562\n",
      "Epoch 117/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4708 - mean_squared_error: 0.1561\n",
      "Epoch 118/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4706 - mean_squared_error: 0.1560\n",
      "Epoch 119/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4704 - mean_squared_error: 0.1558\n",
      "Epoch 120/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4688 - mean_squared_error: 0.1553\n",
      "Epoch 121/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4683 - mean_squared_error: 0.1552\n",
      "Epoch 122/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4705 - mean_squared_error: 0.1558\n",
      "Epoch 123/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4694 - mean_squared_error: 0.1555\n",
      "Epoch 124/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4688 - mean_squared_error: 0.1552\n",
      "Epoch 125/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4676 - mean_squared_error: 0.1548\n",
      "Epoch 126/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4679 - mean_squared_error: 0.1549\n",
      "Epoch 127/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4670 - mean_squared_error: 0.1548\n",
      "Epoch 128/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4653 - mean_squared_error: 0.1540\n",
      "Epoch 129/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4659 - mean_squared_error: 0.1542\n",
      "Epoch 130/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4653 - mean_squared_error: 0.1539\n",
      "Epoch 131/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4651 - mean_squared_error: 0.1541\n",
      "Epoch 132/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4656 - mean_squared_error: 0.1541\n",
      "Epoch 133/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4647 - mean_squared_error: 0.1539\n",
      "Epoch 134/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4652 - mean_squared_error: 0.1540\n",
      "Epoch 135/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4641 - mean_squared_error: 0.1536\n",
      "Epoch 136/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4635 - mean_squared_error: 0.1535\n",
      "Epoch 137/150\n",
      "609/609 [==============================] - 2s 2ms/step - loss: 0.4622 - mean_squared_error: 0.1531\n",
      "Epoch 138/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4629 - mean_squared_error: 0.1533\n",
      "Epoch 139/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4632 - mean_squared_error: 0.1533\n",
      "Epoch 140/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4625 - mean_squared_error: 0.1530\n",
      "Epoch 141/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4609 - mean_squared_error: 0.1524\n",
      "Epoch 142/150\n",
      "609/609 [==============================] - 2s 3ms/step - loss: 0.4610 - mean_squared_error: 0.1525\n",
      "Epoch 143/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4628 - mean_squared_error: 0.1532\n",
      "Epoch 144/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4611 - mean_squared_error: 0.1526\n",
      "Epoch 145/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4601 - mean_squared_error: 0.1522\n",
      "Epoch 146/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4610 - mean_squared_error: 0.1524\n",
      "Epoch 147/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4606 - mean_squared_error: 0.1524\n",
      "Epoch 148/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4596 - mean_squared_error: 0.1520\n",
      "Epoch 149/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4614 - mean_squared_error: 0.1527\n",
      "Epoch 150/150\n",
      "609/609 [==============================] - 1s 2ms/step - loss: 0.4577 - mean_squared_error: 0.1513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f57e8204700>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 1s 2ms/step - loss: 0.4509 - mean_squared_error: 0.1489\n",
      "Accuracy: 14.89\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../data_acquisition/data_0.3/data_game_values_test_odds.csv\", sep=\";\").dropna()\n",
    "\n",
    "features = np.swapaxes(np.array([test_data[\"home_xG\"] - xg_mean, test_data[\"away_xg_against\"] - xg_against_mean,\n",
    "                                test_data[\"away_xG\"] - xg_mean, test_data[\"home_xg_against\"] - xg_against_mean,\n",
    "                                test_data[\"home_xT_all\"] - xt_mean, test_data[\"away_xT_all\"] - xt_mean,\n",
    "                                test_data[\"home_xt_all_against\"] - xt_against_mean, test_data[\"away_xt_all_against\"] - xt_against_mean]), 0, 1)\n",
    "# features_a = np.swapaxes(np.array([train_data[\"away_xG\"], train_data[\"away_xT_only_pos\"], train_data[\"home_xg_against\"], train_data[\"home_xt_only_pos_against\"]]), 0, 1)\n",
    "\n",
    "gi = np.swapaxes(np.array([test_data[\"home_gi\"], test_data[\"away_gi\"]]), 0, 1)\n",
    "# gi_a = np.swapaxes(np.array([train_data[\"away_gi\"]]), 0, 1)\n",
    "\n",
    "form = np.swapaxes(np.array([(test_data[\"ha_form_home_for\"] / 5) - form_for_mean, (test_data[\"ha_form_home_against\"] / 5) - form_against_mean,\n",
    "                            (test_data[\"ha_form_away_for\"] / 5) - form_for_mean, (test_data[\"ha_form_away_against\"] / 5) - form_against_mean]), 0, 1)\n",
    "\n",
    "goals = np.swapaxes(np.array([test_data[\"home_score\"], test_data[\"away_score\"]]), 0, 1)\n",
    "\n",
    "elo = np.swapaxes(np.array([(test_data[\"elo_home\"] / 1000) - (test_data[\"elo_away\"] / 1000)]), 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals_clas = [np.array([1, 0, 0]) if x[0] > x[1] else np.array([0, 1, 0]) if x[0] == x[1] else np.array([0, 0, 1]) for x in goals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate([features, form, elo], axis=1)\n",
    "y_test = np.array(goals_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred, act = [], []\n",
    "# for idx, i in enumerate(np.round(predictions)):\n",
    "#     if i[0] > i[1]:\n",
    "#         pred.append(0)\n",
    "#     if i[0] == i[1]:\n",
    "#         pred.append(1)\n",
    "#     if i[0] < i[1]:\n",
    "#         pred.append(2)\n",
    "#     if y_test[idx][0] > y_test[idx][1]:\n",
    "#         act.append(0)\n",
    "#     if y_test[idx][0] == y_test[idx][1]:\n",
    "#         act.append(1)\n",
    "#     if y_test[idx][0] < y_test[idx][1]:\n",
    "#         act.append(2)\n",
    "    \n",
    "# df = pd.DataFrame({\"act\": act, \"pred\": pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, act = [], []\n",
    "for idx, i in enumerate(np.round(predictions)):\n",
    "    pred.append(np.argmax(i))\n",
    "    if y_test[idx][0] > y_test[idx][1]:\n",
    "        act.append(0)\n",
    "    if y_test[idx][0] == y_test[idx][1]:\n",
    "        act.append(1)\n",
    "    if y_test[idx][0] < y_test[idx][1]:\n",
    "        act.append(2)\n",
    "    \n",
    "df = pd.DataFrame({\"act\": act, \"pred\": pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "act     0.144337\n",
       "pred    0.144337\n",
       "dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df[df[\"act\"] == df[\"pred\"]]) / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1545 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      act  pred\n",
       "0       2     0\n",
       "1       0     1\n",
       "2       0     0\n",
       "3       0     0\n",
       "4       1     0\n",
       "...   ...   ...\n",
       "1540    1     2\n",
       "1541    0     0\n",
       "1542    1     1\n",
       "1543    2     0\n",
       "1544    1     2\n",
       "\n",
       "[1545 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packing-report",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "712082fa5832080cfbc451c8f4e95f25cd39c626d7d8aebf8310513402cfb031"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
