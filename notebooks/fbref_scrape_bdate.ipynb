{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper.footballsquads_scraper import Footballsquads_scraper\n",
    "from database_io.db_handler import DB_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbh = DB_handler(\"/home/morten/Develop/packing-report/gde/GDE.db\")\n",
    "fh = Footballsquads_scraper(\"/home/morten/Develop/packing-report/gde/.cache_footballsquads/\", dbh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh.cache_to_db(leagues=[\"GER-Bundesliga\", \"GER-Bundesliga2\", \"ENG-Premier League\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh.scrape_archive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_html = fh.scrape_kit_number_table(\"http://www.footballsquads.co.uk/eng/2002-2003/conf/scar.htm\")\n",
    "table_dict = fh.extract_numbers_from_html_table(table_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"/home/morten/Develop/packing-report/Goal-Difference-Elo-GDE/.cache_footballsquads/ger-2021-2022-gerbun-monchen.pckl\",'rb')\n",
    "to = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(url):\n",
    "    all_rows = []\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(\"http://www.footballsquads.co.uk/ger/2021-2022/bundes/monchen.htm\")\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Find the table you want to scrape by inspecting the HTML source\n",
    "        table = soup.find(\"div\", {\"id\": \"main\"})\n",
    "\n",
    "        if table:\n",
    "            # Extract table rows\n",
    "            rows = table.find_all(\"tr\")\n",
    "\n",
    "            # Loop through rows and extract data\n",
    "            for row in rows:\n",
    "                # Extract table data from each row\n",
    "                cells = row.find_all([\"th\", \"td\", \"i\"], recursive=True)\n",
    "                row_data = []\n",
    "                for cell in cells:\n",
    "                    # Check if the cell contains italic text\n",
    "                    italic_text = cell.find(\"i\")\n",
    "                    if italic_text:\n",
    "                        # If italic text is present, add it to row_data\n",
    "                        row_data.append(italic_text.get_text(strip=True))\n",
    "                    else:\n",
    "                        # If no italic text, add the regular text\n",
    "                        row_data.append(cell.get_text(strip=True))\n",
    "                # Print row data\n",
    "                all_rows.append(row_data)\n",
    "        else:\n",
    "            print(\"Table not found on the page.\")\n",
    "        print(all_rows)\n",
    "    else:\n",
    "        print(\"Failed to fetch the page. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_url = f\"http://www.footballsquads.co.uk/ger/2021-2022/bundes/monchen.htm\"\n",
    "team_name = \"monchen\"\n",
    "file_path = f\"ger-bundes-2020-2021-{team_name}.pckl\"\n",
    "if file_path not in os.listdir(\"/home/morten/Develop/packing-report/Goal-Difference-Elo-GDE/.cache_footballsquads\"):\n",
    "    print(\"Scraping \", scrape_url)\n",
    "else:\n",
    "    print(\"Data found in cache, skip\")\n",
    "data = get_table(scrape_url)\n",
    "if not data:\n",
    "    print(\"None Data found!\")\n",
    "with open(\"/home/morten/Develop/packing-report/Goal-Difference-Elo-GDE/.cache_footballsquads/\" + file_path, 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data='''<table>\n",
    "<tr>\n",
    "   <td>10</td>\n",
    "   <td>Thuram</td>\n",
    "</tr>\n",
    "<tr>\n",
    "   <td>11</td>\n",
    "   <td>\n",
    "      <i>Wolf </i>  \n",
    "   </td>\n",
    "</tr>\n",
    "</table>'''\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(data,'html.parser')\n",
    "\n",
    "for child in soup.find('table').findChildren(\"tr\" , recursive=False):\n",
    "  tdlist = []\n",
    "  if child.find('table'):\n",
    "     for td in child.findChildren(\"td\", recursive=False):\n",
    "         print(td.next_element.strip())\n",
    "         for td1 in td.findChildren(\"table\", recursive=False):\n",
    "             for child1 in td1.findChildren(\"tr\", recursive=False):\n",
    "                 for child2 in child1.findChildren(\"td\", recursive=False):\n",
    "                     tdlist.append(child2.text)\n",
    "                 print(' '.join(tdlist))\n",
    "                 print(child2.next_element.next_element.strip())\n",
    "  else:\n",
    "     for td in child.findChildren(\"td\" , recursive=False):\n",
    "         tdlist.append(td.text)\n",
    "     print(' '.join(tdlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packing-report",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
